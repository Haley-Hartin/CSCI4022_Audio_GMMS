{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "from statistics import mode\n",
    "import sys\n",
    "import aubio\n",
    "import os\n",
    "import wget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for extracting Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beats_to_bpm(beats, path):\n",
    "    # if enough beats are found, convert to periods then to bpm\n",
    "    if len(beats) > 1:\n",
    "        if len(beats) < 4:\n",
    "            print(\"few beats found in {:s}\".format(path))\n",
    "        bpms = 60./np.diff(beats)\n",
    "        return np.median(bpms)\n",
    "    else:\n",
    "        print(\"not enough beats\")\n",
    "        return 0\n",
    "\n",
    "def get_tempo(path):\n",
    "    \n",
    "    samplerate, win_s, hop_s = 44100, 1024, 256\n",
    "    src = aubio.source(path, samplerate, hop_s)\n",
    "    samplerate = src.samplerate\n",
    "    o = aubio.tempo(\"specdiff\", win_s, hop_s, samplerate)\n",
    "\n",
    "    beats = []\n",
    "        # Total number of frames read\n",
    "    total_frames = 0\n",
    "    while True:\n",
    "        samples, read = src()\n",
    "        is_beat = o(samples)\n",
    "        if is_beat:\n",
    "            this_beat = o.get_last_s()\n",
    "            beats.append(this_beat)\n",
    "            #if o.get_confidence() > .2 and len(beats) > 2.:\n",
    "            #    break\n",
    "            total_frames += read\n",
    "        if read < hop_s:\n",
    "            break\n",
    "    return beats_to_bpm(beats, path)\n",
    "\n",
    "def get_energy(path):\n",
    "    \n",
    "    win_s = 512                 # fft size\n",
    "    hop_s = win_s  \n",
    "    samplerate =0\n",
    "    s = aubio.source(path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "\n",
    "    pv = aubio.pvoc(win_s, hop_s)\n",
    "\n",
    "    f = aubio.filterbank(40, win_s)\n",
    "    f.set_mel_coeffs_slaney(samplerate)\n",
    "\n",
    "    energies = np.zeros((40,))\n",
    "    o = {}\n",
    "\n",
    "    total_frames = 0\n",
    "    downsample = 2\n",
    "\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        fftgrain = pv(samples)\n",
    "        new_energies = f(fftgrain)\n",
    "       \n",
    "        energies = np.vstack( [energies, new_energies] )\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "    return np.mean(energies)\n",
    "\n",
    "def get_pitch(path):\n",
    "    \n",
    "    downsample = 1\n",
    "    samplerate = 44100 \n",
    "    win_s = 4096 \n",
    "    hop_s = 512  \n",
    "    tolerance = 0.8\n",
    "\n",
    "    s = aubio.source(path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "\n",
    "    pitch_o = aubio.pitch(\"yin\", win_s, hop_s, samplerate)\n",
    "    pitch_o.set_unit(\"midi\")\n",
    "    pitch_o.set_tolerance(tolerance)\n",
    "    total_frames = 0\n",
    "    pitches = []\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        pitch = pitch_o(samples)[0]\n",
    "        pitches += [pitch]\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "    return(np.mean(pitches))\n",
    "\n",
    "def get_notes(path):\n",
    "    downsample = 1\n",
    "    samplerate = 44100 \n",
    "    win_s = 512 \n",
    "    hop_s = 256 \n",
    "\n",
    "    s = aubio.source(path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "    notes = []\n",
    "\n",
    "    tolerance = 0.8\n",
    "    notes_o = aubio.notes(\"default\", win_s, hop_s, samplerate)\n",
    "\n",
    "\n",
    "    # total number of frames read\n",
    "    total_frames = 0\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        new_note = notes_o(samples)\n",
    "        if(new_note[0] != 0):\n",
    "            for n in new_note:\n",
    "                if(n not in notes):\n",
    "                    notes.append(n)\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "\n",
    "    return len(notes)\n",
    "\n",
    "def get_onset(path):\n",
    "    \n",
    "    win_s = 512                \n",
    "    hop_s = win_s\n",
    "    samplerate = 0\n",
    "\n",
    "\n",
    "    s = aubio.source(path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "    o = aubio.onset(\"default\", win_s, hop_s, samplerate)\n",
    "\n",
    "    # list of onsets, in samples\n",
    "    onsets = []\n",
    "\n",
    "    # total number of frames read\n",
    "    total_frames = 0\n",
    "    \n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        if o(samples):\n",
    "            onsets.append(o.get_last())\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "    \n",
    "    diff = 0\n",
    "    first = True\n",
    "    last = 0\n",
    "    cntr = 0\n",
    "    for i in onsets:\n",
    "        if(not first):\n",
    "            diff+=abs(i-last)\n",
    "            cntr+=1\n",
    "        first = False\n",
    "        last = i\n",
    "\n",
    "    if(cntr ==0): return 0 \n",
    "    return i/cntr\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data\n",
    "***\n",
    "## Read in Songs from Spotify API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to spotify API using Spotipy\n",
    "cid =\"12b051049eb14a05ac3dd252770b6bd3\" \n",
    "secret = \"8844a8e5f63f4fa3998ba69811b2e005\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = []\n",
    "track_name = []\n",
    "popularity = []\n",
    "track_id = []\n",
    "genres = []\n",
    "audio = []\n",
    "#changed to 300 for testing\n",
    "#loading in 100 different tracks from 2010 with Spotipy\n",
    "for i in range(0,300,10):\n",
    "    track_results = sp.search(q='year:2010', type='track', limit=10,offset=i)\n",
    "    for i, t in enumerate(track_results['tracks']['items']):\n",
    "        #only execpt songs with a audio url\n",
    "        if(t['preview_url']):\n",
    "            \n",
    "            previewUrl = t['preview_url']\n",
    "            name = t['name']\n",
    "            name = name.replace('/', '')\n",
    "            name = name.replace(':', '')\n",
    "            \n",
    "            try:\n",
    "                #Download preview from Spotify\n",
    "                filepath = os.path.join(os.getcwd(), 'audioFiles', name )\n",
    "                filename = wget.download(previewUrl, out=filepath)\n",
    "\n",
    "                #populating lists we will use for DF later\n",
    "                artist_name.append(t['artists'][0]['name'])\n",
    "                track_name.append(t['name'])\n",
    "                track_id.append(t['id'])\n",
    "                popularity.append(t['popularity'])\n",
    "                artist = sp.artist(t[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "                genres.append(artist[\"genres\"]) \n",
    "                audio.append(filename)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#storing data in dataframe\n",
    "df_tracks = pd.DataFrame({'artist_name':artist_name,'track_name':track_name,'track_id':track_id,'popularity':popularity})\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "batchsize = 100\n",
    "\n",
    "#Create list of audio features for each song\n",
    "for i in range(0,len(df_tracks['track_id']),batchsize):\n",
    "    batch = df_tracks['track_id'][i:i+batchsize]\n",
    "    feature_results = sp.audio_features(batch)\n",
    "    for i, t in enumerate(feature_results):\n",
    "        if t != None:\n",
    "            rows.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing audio feature data of each song in a dataframe\n",
    "df_audio_features = pd.DataFrame.from_dict(rows,orient='columns')\n",
    "print(\"Shape of the dataset:\", df_audio_features.shape)\n",
    "df_audio_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aubio Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo=[]\n",
    "energy=[]\n",
    "pitch=[]\n",
    "onset=[]\n",
    "notes=[]\n",
    "for song in audio:\n",
    "    tempo.append(get_tempo(song))\n",
    "    energy.append(get_energy(song))\n",
    "    pitch.append(get_pitch(song))\n",
    "    onset.append(get_onset(song))\n",
    "    notes.append(get_notes(song))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aubio_features = pd.DataFrame({'artist_name':artist_name,'track_name':track_name,'tempo':tempo,'energy':energy,'pitch':pitch,'onset':onset, 'notes':notes})\n",
    "df_aubio_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM algo to create GMMs\n",
    "def EM(dat, k, n):\n",
    "    \n",
    "    p_class=np.zeros(k)\n",
    "    means=np.zeros((k,n))\n",
    "    covars=np.zeros((k,n,n))\n",
    "    mean_dist=np.array(0)\n",
    "    p_data_given_class=np.zeros((len(dat),k))\n",
    "\n",
    "    \n",
    "    #initializations\n",
    "    init_idx=np.random.choice(range(len(dat)), size=k, replace=False)\n",
    "    \n",
    "    for dim in range(k):\n",
    "        covars[dim,:,:]=np.cov(np.transpose(dat))\n",
    "        means[dim,:]=dat.iloc[init_idx[dim]]\n",
    "        p_class[dim]=1/k\n",
    "    for step in range(50):  \n",
    "        #Bayes stuff: pdfs then pdf*mixtures, then normalize\n",
    "        for dim in range(k):\n",
    "            p_data_given_class[:,dim]=  np.array([stats.multivariate_normal.pdf(x=dat, mean=means[dim,:], cov=covars[dim,:,:])])\n",
    "        p_class_given_data=p_data_given_class*p_class\n",
    "\n",
    "        sums=np.sum(p_class_given_data, axis=1)\n",
    "        for dim in range(k):\n",
    "            p_class_given_data[:,dim]=p_class_given_data[:,dim]*(1/sums)\n",
    "        n_class = np.sum(p_class_given_data, axis=0)\n",
    "        p_class=n_class/len(dat)\n",
    "\n",
    "        # mean and covar updates\n",
    "        for dim in range(k):\n",
    "            for f1 in range(n):\n",
    "                means[dim,f1]=np.sum(p_class_given_data[:,dim]*dat.iloc[:,f1])*(1/n_class[dim])\n",
    "                \n",
    "                for f2 in range(n):\n",
    "                    if (f1==f2):\n",
    "                        covars[dim,f1,f2]=np.sum(p_class_given_data[:,dim]*((dat.iloc[:,f1]-means[dim,f1])**2))*(1/n_class[dim])\n",
    "                    else:\n",
    "                        covars[dim,f1,f2]=np.sum(p_class_given_data[:,dim]*(dat.iloc[:,f1]-means[dim,f1])*(dat.iloc[:,f2]-means[dim,f2]))*(1/n_class[dim])                                                           \n",
    "    mean_dist=0\n",
    "    \n",
    "    for pt in range(len(dat)):\n",
    "        for dim in range(k):\n",
    "            #for each datum-mean pair, compute their prob-weighted distance apart\n",
    "            mean_dist+=np.sqrt(np.sum((means[dim,:]-np.array(dat.iloc[pt]))**2)*p_class_given_data[pt,dim])\n",
    "    mean_dist=mean_dist/(len(dat)*k)\n",
    "    return p_class, means, covars, mean_dist, p_class_given_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GMM for k=2,4,6,8,10 clusters for Spotify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GMMs with various K values to find the best K value to use\n",
    "test_df = df_audio_features[['acousticness', 'energy', 'tempo', 'liveness', 'valence']]\n",
    "\n",
    "p2, m2, c2,d2, pc2 = EM(test_df,2, 5)\n",
    "p4, m4, c4,d4, pc4 = EM(test_df,4, 5)\n",
    "p6, m6, c6,d6, pc6  = EM(test_df,6, 5)\n",
    "p8, m8, c8,d8, pc8  = EM(test_df,8, 5)\n",
    "p10, m10, c10,d10, pc10  = EM(test_df,10, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GMM for k=2,4,6,8,10 clusters for Aubio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df_aubio_features = df_aubio_features[['notes','tempo','energy','pitch','onset' ]]\n",
    "\n",
    "\n",
    "ap2, am2, ac2,ad2, apc2 = EM(test_df_aubio_features,2, 5)\n",
    "ap4, am4, ac4,ad4, apc4 = EM(test_df_aubio_features,4, 5)\n",
    "ap6, am6, ac6,ad6, apc6  = EM(test_df_aubio_features,6, 5)\n",
    "ap8, am8, ac8,ad8, apc8  = EM(test_df_aubio_features,8, 5)\n",
    "ap10, am10, ac10,ad10, apc10  = EM(test_df_aubio_features,10, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide which k value is the best to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([2,4,6,8, 10], [d2,d4,d6,d8, d10], label = \"Spotify Audio Features\")\n",
    "plt.plot([2,4,6,8, 10], [ad2,ad4,ad6,ad8, ad10], label = \"Aubio Audio Features\")\n",
    "plt.title('Average Distance to Centroid');\n",
    "plt.xlabel(\"K\")\n",
    "plt.xlabel(\"Distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 6 Audio features, it appers the k=4 is the best k value to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clusters for Spotify GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_clusters = []\n",
    "for pt in pc4:\n",
    "    max_prob = max(pt)\n",
    "    spotify_clusters.append(np.where(pt ==  max_prob)[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clusters for Aubio GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aubio_clusters = []\n",
    "for apt in apc4:\n",
    "    max_prob = max(apt)\n",
    "    aubio_clusters.append(np.where(apt ==  max_prob)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PCA to find the two most related dimensions for our plot - Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to find the two most related dimensions to plot\n",
    "M = pd.DataFrame(test_df).values\n",
    "MT = np.transpose(M)\n",
    "MTM = np.matmul(MT, M)\n",
    "\n",
    "\n",
    "#Decomposition of given data matrix\n",
    "evals, evecs = np.linalg.eig(MTM)\n",
    "np.sum(evecs[:,0]**2)\n",
    "evals_sorted =  np.flip(np.sort(evals),0)\n",
    "\n",
    "# Get the sorted list of indices for the eigenvalues\n",
    "idx_sorted = [list(evals).index(ee) for ee in evals_sorted]\n",
    "\n",
    "E = evecs[:,idx_sorted]\n",
    "#Rotated M by E\n",
    "spotify_ME2 = np.matmul(M, E[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x = []\n",
    "s_y = []\n",
    "for i in range(spotify_ME2.shape[0]):\n",
    "    s_x.append(spotify_ME2[i,0])\n",
    "    s_y.append(spotify_ME2[i,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PCA to find the two most related dimensions for our plot - Aubio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to find the two most related dimensions to plot\n",
    "M = pd.DataFrame(test_df_aubio_features).values\n",
    "MT = np.transpose(M)\n",
    "MTM = np.matmul(MT, M)\n",
    "\n",
    "\n",
    "#Decomposition of given data matrix\n",
    "evals, evecs = np.linalg.eig(MTM)\n",
    "np.sum(evecs[:,0]**2)\n",
    "evals_sorted =  np.flip(np.sort(evals),0)\n",
    "\n",
    "# Get the sorted list of indices for the eigenvalues\n",
    "idx_sorted = [list(evals).index(ee) for ee in evals_sorted]\n",
    "\n",
    "E = evecs[:,idx_sorted]\n",
    "#Rotated M by E\n",
    "aubio_ME2 = np.matmul(M, E[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_x = []\n",
    "a_y = []\n",
    "for i in range(aubio_ME2.shape[0]):\n",
    "    a_x.append(aubio_ME2[i,0])\n",
    "    a_y.append(aubio_ME2[i,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters using the two most related dimensions\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.set_title('k=4 Spotify GMM ')\n",
    "ax.scatter(s_x,s_y, c=spotify_clusters)\n",
    "ax.set_xlabel('Primary Eigen Vector')\n",
    "ax.set_ylabel('Second largest Eigen Vector')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.set_title('k=4 Aubio GMM')\n",
    "ax.scatter(a_x,a_y, c=aubio_clusters)\n",
    "ax.set_xlabel('Primary Eigen Vector')\n",
    "ax.set_ylabel('Second largest Eigen Vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most common genres from each cluster accoridng to Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all the songs in the first cluster\n",
    "index = 0\n",
    "c1_genre = []\n",
    "c2_genre = []\n",
    "c3_genre = []\n",
    "c4_genre = []\n",
    "for song in spotify_clusters:\n",
    "    if(song == 0):\n",
    "        c1_genre.append(genres[index])\n",
    "    if(song == 1):\n",
    "        c2_genre.append(genres[index])\n",
    "    if(song == 2):\n",
    "        c3_genre.append(genres[index])\n",
    "    if(song == 3):\n",
    "        c4_genre.append(genres[index])\n",
    "    index = index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_flat = [x for sublist in c1_genre for x in sublist]\n",
    "c2_flat = [x for sublist in c2_genre for x in sublist]\n",
    "c3_flat = [x for sublist in c3_genre for x in sublist]\n",
    "c4_flat = [x for sublist in c4_genre for x in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_genres(n, data):\n",
    "    \n",
    "    df=pd.DataFrame(data = {'Number': data})\n",
    "    df1 = pd.DataFrame(df['Number'].value_counts())\n",
    "    return  df1['Number'].index[:n,]\n",
    "\n",
    "print(\"Cluster 1 most common genres: \",  get_popular_genres(4, c1_flat).values)\n",
    "print(\"Cluster 2 most common genres: \",  get_popular_genres(4, c2_flat).values)\n",
    "print(\"Cluster 3 most common genres: \",  get_popular_genres(4, c3_flat).values)\n",
    "print(\"Cluster 4 most common genres: \",  get_popular_genres(4, c4_flat).values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the probabilty a new song belong to each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather 10 new songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = []\n",
    "track_name = []\n",
    "popularity = []\n",
    "track_id = []\n",
    "genres = []\n",
    "\n",
    "#loading in 10 different tracks from 2021 with Spotipy\n",
    "for i in range(10):\n",
    "    track_results = sp.search(q='year:2020', type='track', limit=1,offset=i)\n",
    "    for i, t in enumerate(track_results['tracks']['items']):\n",
    "        #populating lists we will use for DF later\n",
    "        artist_name.append(t['artists'][0]['name'])\n",
    "        track_name.append(t['name'])\n",
    "        track_id.append(t['id'])\n",
    "        popularity.append(t['popularity'])\n",
    "        artist = sp.artist(t[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "        genres.append(artist[\"genres\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing data in dataframe\n",
    "df_new_tracks = pd.DataFrame({'artist_name':artist_name,'track_name':track_name,'track_id':track_id,'popularity':popularity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "batchsize = 10\n",
    "\n",
    "# Create list of audio features for each song\n",
    "for i in range(0,len(df_new_tracks['track_id']),batchsize):\n",
    "    batch = df_tracks['track_id'][i:i+batchsize]\n",
    "    feature_results = sp.audio_features(batch)\n",
    "    for i, t in enumerate(feature_results):\n",
    "        if t != None:\n",
    "            rows.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Audio Featureds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing audio feature data of each song in a dataframe\n",
    "df_new_audio_features = pd.DataFrame.from_dict(rows,orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = df_new_audio_features[['acousticness', 'energy', 'tempo',  'liveness', 'valence']]\n",
    "new_testt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the probability a song belongs to each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to compute the probabilty a new song belongs to each genre (cluster)\n",
    "def p_class_given_data(song, k, means, covars, p_class):\n",
    "    p_song_given_cluster = []\n",
    "    p_cluster_given_song = []\n",
    "    for cluster in range(k):\n",
    "        p_song_given_cluster.append( stats.multivariate_normal.pdf(x=song, mean=means[cluster], cov=covars[cluster]))\n",
    "        p_cluster_given_song.append( p_song_given_cluster[cluster] * p_class[cluster] )\n",
    "    \n",
    "    summ = sum(p_cluster_given_song)\n",
    "    \n",
    "    for cluster in range(k):\n",
    "        p_cluster_given_song[cluster] = p_cluster_given_song[cluster] / summ\n",
    "    \n",
    "    return  p_cluster_given_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(10):\n",
    "    song = list(new_test_df.iloc[index].values)\n",
    "    probs = p_class_given_data(song, 4, m4, c4, p4)\n",
    "\n",
    "\n",
    "    print(\"probability of belonging to cluster 0 with genres\", get_popular_genres(4, c1_flat).values, \":\", probs[0].round(4))\n",
    "    print(\"probability of belonging to cluster 1 with genres\", get_popular_genres(4, c2_flat).values, \":\", probs[1].round(4))\n",
    "    print(\"probability of belonging to cluster 2 with genres\", get_popular_genres(4, c3_flat).values, \":\", probs[2].round(4))\n",
    "    print(\"probability of belonging to cluster 3 with genres\", get_popular_genres(4, c4_flat).values, \":\", probs[3].round(4))\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #todo \n",
    "#     probs = p_class_given_data(song, 4, am4, ac4, ap4)\n",
    "# see if the probabilities are the same\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
